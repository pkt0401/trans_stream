1
00:00:08,711 --> 00:00:12,516
それでは、これからテキストを抽出する実習を行っていきます。

2
00:00:13,326 --> 00:00:30,176
実習で使う文書は、情報通信政策研究院発行『딥시크가 촉발한 AI 패러다임 변화와 정책 방향（ディープシークが引き起こしたAIパラダイムの変化と政策の方向性）』です。PDFからテキストを抽出する前に、LangChainの基本ドキュメントオブジェクトDocumentを説明します。

3
00:00:31,858 --> 00:00:39,378
ドキュメントには文書内容を表すページコンテンツとメタ情報をディクショナリ形式で表すメタデータがあります。

4
00:00:41,341 --> 00:00:59,375
LangChainにドキュメントオブジェクトを読み込み、「こんにちは、これはLangChainのドキュメントです。」という文字列をページコンテンツとして追加します。ドキュメントの属性を確認すると、メタデータはなく、ページコンテンツに入力した文字列が追加されていることがわかります。

5
00:01:00,316 --> 00:01:15,664
次にメタデータを追加してみます。データのソース、ページ、著者、そして日付、この4つの情報を追加し、ドキュメントの属性を再度確認すると、追加したメタデータが辞書の形で追加されていることが確認できます。

6
00:01:16,144 --> 00:01:46,956
次はドキュメントローダーについてです。ドキュメントローダーは、さまざまなファイル形式から内容を読み込み、ドキュメントオブジェクトに変換する役割を果たします。 拡張子によって、PDFローダーやCSVローダーなどさまざまなローダーがあり、処理する文書に応じて適切に使い分ければよいです。 サンプルファイルを読み込んだ後、今回の実習で使用するサンプルファイルはPDFなので、PDFローダーを使います。 ローダーを設定し、ロードメソッドを使ってPDFのテキストを読み込みます。

7
00:01:49,178 --> 00:02:08,606
ロードされた文書の長さを確認すると46、つまり46であることが分かりますが、これは私たちが使っている実習ファイルの100ページのうち46ページ分がページ単位で分割されたことを示しています。 11番目の文書の内容を確認してみると

8
00:02:12,389 --> 00:02:22,574
ページの内容がページコンテンツに含まれており、ページ番号やファイル名など、さまざまなメタ情報がメタデータに追加されていることが分かります。

9
00:02:23,854 --> 00:02:41,085
次はロード・アンド・スプリットです。 スプリッターは理論の時間にお話ししたように、抽出された文書を複数のチャンクに分割できるツールですが、load and splitは文書を返す際に最初から分割された形で返され、返された結果はドキュメントのリスト形式になります。

10
00:02:41,786 --> 00:02:58,210
LangChainのスプリッターの中から、recursiveTextSplitterを使ってみます。 文字を分割するスプリッターのチャンクサイズはにひゃく、つまり長さがにひゃくになるように切り、オーバーラップは前後のチャンク間で重複がないように設定します。

11
00:02:59,290 --> 00:03:03,091
先ほどと同じようにpyPDFLoaderを使ってロードします。

12
00:03:05,111 --> 00:03:21,862
PDFの文字列をロードする際に、スプリッターも一緒に指定します。 このようにロードされたドキュメントを確認すると、ドキュメントの長さが二百七であることが分かり、一ページ内でも複数のチャンクに分割されていることが分かります。

13
00:03:23,102 --> 00:03:39,868
51番目チャンクを確認すると、14ページ一部がページコンテンツに含まれていると分かります。次に、PDFを処理するさまざまなローダーについて見ていきましょう。現実では、多くの文書がPDF形式でやり取りされることがよくあります。

14
00:03:41,230 --> 00:04:19,393
今回の実習では、PDF文書をドキュメント形式でロードする方法を学びます。LangChainには多様なPDFパーサーが統合されているため、簡単に利用できます。ただし、サーチャブルPDFでなくスキャン画像形式のPDFの場合はOCRが必要で、現時点ではOCRの韓国語認識性能は十分ではありません。さまざまなPDFローダーで多くの実験を行い、自分が処理すべき文書に最適なローダーを選ぶことが重要です。次は、オートレグチームが複数ドメインの文書でPDFローダーの抽出性能を実験した結果です。

15
00:04:21,555 --> 00:04:44,133
医療分野の文書ではPDFMinerの性能が最も良く、法律文書ではPDFPlumberとPDFFileの性能が最も高いことが分かりました。 私たちも今後取り組むべき多くの課題において、必要な文書を基準にさまざまなライブラリで実験を行い、その結果を比較して最も性能の高いライブラリを選択できるようにしなければなりません。

16
00:04:45,954 --> 00:05:03,912
このほかにも、Azureが提供するDocument IntelligenceやAmazonのTextractなどのサービスも利用できます。私たちがさまざまなプロジェクトを進めてきた中で、AzureのDocument Intelligenceの性能が最も高く、今でも多くのプロジェクトの文書処理段階で広く活用されています。

17
00:05:05,038 --> 00:05:16,701
まず、PyPDF Loaderは先ほども使用しましたが、もう一度見てみると、LangChainにPyPDF Loaderを設定してPDFをロードすると、全体の長さが

18
00:05:22,203 --> 00:05:33,146
46のドキュメントオブジェクトが作成されることになります。 全体のメタデータを出力してみると、下記のような情報がメタデータとして追加されていることが確認できます。

19
00:05:34,442 --> 00:05:54,098
しかし、スキャンされた文書のようなイメージPDFの場合、PyPDF Loaderを利用してもページのコンテンツを抽出することはできません。 スキャンされたPDFファイルである「Public Water Mass Mailing」というファイルをPyPDF Loaderで同じようにロードしてみると、

20
00:05:56,140 --> 00:05:59,403
このようにページのコンテンツには何も含まれなくなります。

21
00:06:00,523 --> 00:06:12,533
イメージPDFは単なるPDFローダーでは対応できません。 RapidOCR ONIXというライブラリも一緒にインストールし、画像からもテキストが抽出できるようにする必要があります。

22
00:06:16,076 --> 00:06:35,531
PDFローダーを設定する際に「Extract Images」というオプションをTrueにすると、画像からもテキストを抽出できるようになりますが、OCR処理が入るため、検索可能なPDFからテキストを抽出する場合に比べてリソースが必要で、多少時間がかかることがあります。

23
00:06:36,972 --> 00:06:45,719
ドキュメントの内容を一部出力してみると、ページのコンテンツにどのような内容が入っているかを確認できます。 次はPyMu PDFです。

24
00:06:46,459 --> 00:07:00,410
PyPDFと同じ方法でLangChainにPyMu PDFローダーを呼び出し、ローダーを設定した後にPDFをロードすると、ページコンテンツの内容が抽出されていることを確認できます。

25
00:07:02,770 --> 00:07:13,314
ここでも同様に、OCRが必要なドキュメントの場合はExtract ImagesオプションをTrueに設定して抽出すると、同じようにテキストが抽出されます。

26
00:07:15,455 --> 00:07:24,739
次はPyPDFium 2 ライブラリで、例えばPyPDFローダーやPyMu PDFローダーと同じように🕓使用できます。

27
00:07:26,980 --> 00:07:29,001
最後にPDF Plumberです。

28
00:07:29,661 --> 00:07:36,344
PDF PlumberもPyPDFやPyMu PDFと同様に同じように使用することができます。

29
00:07:37,805 --> 00:07:45,448
次はPDFではなくCSVローダーについて見ていきましょう。 CSVはドキュメントごとにいちぎょうずつロードされます。

30
00:07:46,288 --> 00:08:07,379
LangChainのCSVローダーを使ってCSVローダーを作成し、データをロードすると、全891行がそれぞれドキュメントオブジェクトとして分割されていることが確認できます。 ページコンテンツを確認すると、1行分の内容がページコンテンツとして入っていることがわかります。

31
00:08:08,620 --> 00:08:38,040
このとき、ローダーをカスタマイズすることもでき、CSVのフィールド名を設定したり、区切り文字や引用符についても設定することができます。 最後はフローチャートです。 図式化されたPDFやドキュメントは、単にテキストだけを抽出すると、その意味や情報が失われる可能性があります。 図式化された内容の意味を抽出するため、今回はGPT-four hundred fifty fiveモデルに画像を入力し、解釈して情報を抽出してみます。

32
00:08:39,201 --> 00:08:44,302
まず、前回と同じように実習用のAOAI環境変数を設定します。

33
00:08:46,623 --> 00:08:57,446
モデルはGPT-455のミニモデルを使用します。 まず画像は、理論の時間にご覧いただいたレッグパイプラインを図式化した画像を使用します。

34
00:08:59,126 --> 00:09:12,952
画像をジーピーティーフォー／ファイブモデルの入力として使用するためには、ベース64でエンコードされた画像を使う必要があるので、エンコード関数を作成し、画像をベース64文字列として返します。

35
00:09:14,973 --> 00:09:24,937
その後、画像を解釈できるプロンプトを設定しますが、フローチャートからどのような内容で情報を抽出するかについてのガイドラインを与えます。

36
00:09:25,797 --> 00:09:42,106
ここでは、フローチャートを解釈し、ノード間の関係や意味を抽出するアナリストという役割を与え、全体的なプロセスを各ノードごとに詳しく説明し、全体のプロセスを要約してほしいというプロンプトを出しました。

37
00:09:45,307 --> 00:09:49,270
その後、例えばプロンプトと画像をモデルに入力すると、

38
00:09:51,491 --> 00:09:53,952
次のような結果を得ることができます。

39
00:09:57,758 --> 00:10:15,354
各ノードの主な意味や流れ、そして全体的なプロセスの要約までしっかりと抽出されていることが確認でき、このように抽出された結果は、単に画像からテキストだけを抽出する場合よりも、より多くの情報を得ることができます。

