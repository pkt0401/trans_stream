1
00:00:08,747 --> 00:00:11,149
最後はジェネレーション段階です。

2
00:00:11,910 --> 00:00:25,442
全体のワークフローをもう一度見てみると、プリプロセッシング段階を経てベクターデータベースを構築し、ユーザーの質問はエンベディングされ、ベクターデータベースから類似した内容が検索されます。

3
00:00:26,562 --> 00:00:35,451
その後、検索された内容とユーザーの質問が組み合わされてLLMに渡され、最終的に回答が生成されます。

4
00:00:35,811 --> 00:00:36,832
この過程は特別ですか？

5
00:00:36,832 --> 00:00:41,414
特に詳しく説明する部分がないので、すぐに実習コードを一緒に見ていきましょう。

6
00:00:43,435 --> 00:00:50,939
今回の実習では、RAGの基本的なパイプライン全体をもういちど振り返る時間となります。

7
00:00:54,281 --> 00:00:58,082
RAG構造のためのスケルトンコードだと思っていただければと思います。

8
00:00:59,763 --> 00:01:11,759
各段階ごとにモジュールの内容を課題や特定の状況に合わせて変更しながら、その文書に合った適切な構造を見つけていけると良いと思います。

9
00:01:15,140 --> 00:01:29,728
サンプルとして特定のスプリッターなどがあらかじめ適用されておりますが、各段階でさまざまなオプションを細かく変更を加えながら、その結果をじっくりと比較検討を行ってみてください。

10
00:01:33,330 --> 00:01:48,159
まず、必要なライブラリと環境変数を設定した後、今回のスケルトンコードではPDF、DeepSeek関連のPDFファイルをPyMuPDFローダーを使って利用します。

11
00:01:51,739 --> 00:01:52,519
ぜんたいで

12
00:01:54,343 --> 00:01:57,105
よんじゅうろくページからなる文書がロードされました。

13
00:01:58,986 --> 00:02:02,528
ページの内容を出力してみると、このように書かれています。

14
00:02:02,528 --> 00:02:09,513
ページコンテンツの内容が適切に含まれていることを確認でき、メタデータもこのように確認できます。

15
00:02:11,514 --> 00:02:21,181
PyMuPDFローダーでロードしたテキストを、リカーシブテキストスプリッターを使って文書を分割し、チャンクを作成してみます。

16
00:02:22,182 --> 00:02:31,408
今回はチャンクサイズをごひゃく、オーバーラップをごじゅうに設定して文書を分割してみると、合計で...

17
00:02:32,759 --> 00:02:52,292
はちじゅうろっこのチャンクが作成されます。 この作成されたはちじゅうろっこのチャンクは、エンベディングモデルを通じてエンベディングされ、このチャンク分割された文書や文書群はエンベディングモデルと共にFaiss生成に活用されます。

18
00:02:54,372 --> 00:03:01,938
上で分割したはちじゅうろっこのチャンクがFaissに格納され、ベクターデータベースが生成された過程です。

19
00:03:03,058 --> 00:03:10,465
「メタ」というクエリを入力して、類似した部分や類似した文書を探してみます。

20
00:03:12,926 --> 00:03:22,875
次は、ベクターデータベース自体を検索エンジンとして使用し、文書に含まれている情報を検索する段階です。

21
00:03:25,836 --> 00:03:43,608
リトリーバーに検索したい内容のクエリを入力して検索結果を確認すると、同様にデフォルトがよんなので、全体で類似した文書がよんけん検索されたことが確認できます。

22
00:03:47,622 --> 00:03:50,030
最後に、ジェネレーションの段階は

23
00:03:52,033 --> 00:04:09,780
最初にシステムプロンプトとして、RAGアプリケーションのLLMのシステムプロンプトのような役割を与え、検索された内容はコンテキストに、ユーザーの質問はクエスチョンに入れることになります。 このようにプロンプトテンプレートを作成した後に

24
00:04:12,322 --> 00:04:27,192
生成モデルにはフォーオー ミニモデルを使用し、リトリーバーを通じて得られた内容をコンテキストに、ユーザーの質問をクエスチョンに入れたあと、プロンプトLLMステップを使用します。

25
00:04:27,232 --> 00:04:30,474
String-outpasserを使ってこのようなチェーンを構成します。

26
00:04:33,848 --> 00:04:38,129
生成されたチェーンにクエリを入力して実行してみると

27
00:04:41,048 --> 00:04:46,036
このように最終的な回答が生成されたことを確認できます。

28
00:04:47,966 --> 00:05:07,215
これまでRAG全体のパイプラインの各段階ごとに実習し、全体的な総合実習も行いましたが、ここで個人的にさまざまなことを変えたり、オプションやパラメータも調整しながら多様に実験してみてほしいと思います。
