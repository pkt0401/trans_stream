1
00:00:09,043 --> 00:00:16,366
これまでは、naive-ragと呼ばれる最も基本的な形態のrag構成について見てきました。

2
00:00:17,588 --> 00:00:23,890
しかし、現実にはこのような基本的な構造だけでは解決できないさまざまな限界があります。

3
00:00:24,250 --> 00:00:36,495
まず最初に考えられるのは検索性能に関する問題です。前にオープンブックを例に挙げましたが、検索ができなければ全く回答することができなくなります。

4
00:00:37,056 --> 00:00:54,146
あるいは、検索ができなかったにもかかわらず、でたらめなことを作り上げて話すハルシネーションの問題が発生することもあります。 検索された文書が不正確だったり関連性が低い場合、先ほど述べたハルシネーションのように生成された応答も不正確になる可能性が高くなります。

5
00:00:55,267 --> 00:01:07,713
これらのさまざまな基本的なRAGの問題点を解消するために、RAGは現在も継続的に進化しており、今回は進化した形態のRAGについて一部ご紹介したいと思います。

6
00:01:09,635 --> 00:01:29,406
まずは、アドバンストRAGです。 基本的なRAG方式では検索された文書をそのまま使用していましたが、アドバンストRAGでは検索の前後にさまざまな最適化手法を適用することで、より優れた回答が得られるように改善されています。

7
00:01:31,186 --> 00:01:46,853
このプロセスは大きく分けて、検索前、検索中、検索後の段階に分けることができ、まず検索前のプリリトリーバル段階では、より良い検索結果を導くための手法が含まれます。

8
00:01:48,274 --> 00:01:53,796
まず、検索をうまく行うための第一歩は、データを適切に整理することです。

9
00:01:54,977 --> 00:02:04,483
不要な情報を取り除き、さまざまなメタデータを抽出することで、より精度の高い検索が可能になります。

10
00:02:05,483 --> 00:02:13,810
メタ情報を追加したり、インデックス構造を最適化したりするこれらのプロセスは、検索の速度と正確性の向上に寄与します。

11
00:02:15,572 --> 00:02:20,975
または、質問自体を検索しやすい形に変換する方法もあります。

12
00:02:22,276 --> 00:02:37,924
ユーザーのクエリに文法やスペルの誤りがあれば、それらのエラーを修正したり、関連する同義語や追加の用語を加えることで、より多くの内容が検索されるようにします。

13
00:02:38,685 --> 00:02:45,069
このようにユーザーの質問、つまり検索クエリを変換することで、検索の精度を高めることができます。

14
00:02:46,650 --> 00:02:57,257
次はPost-retrieval段階ですが、これは検索された内容をもとにLLMが最適な回答を生成できるように加工する段階です。

15
00:02:58,399 --> 00:02:59,479
検索された...

16
00:03:00,852 --> 00:03:19,044
複数の文書の中から重要度に基づいてより関連性の高い文書を優先的に配置したり、重複した文書を除去し、信頼性の低い文書をフィルタリングしたり、あるいは複数の文書の中から重要な核心情報を抽出することもできます。

17
00:03:20,044 --> 00:03:30,271
これらの手法が検索前や検索後の最適化手法であり、基本的なRAGから一歩進んだ方法だと言えます。

18
00:03:31,148 --> 00:03:32,890
次はモジュラーRAGです。

19
00:03:33,890 --> 00:03:54,308
モジュラーRAGは、全体のプロセス、つまりインデックス作成からプリリトリーバル、リトリーバル、ポストリトリーバル、そして生成までの全過程をモジュール化したRAG構造です。 このように各段階がモジュール化されることで、それぞれの段階を独立して改善できるという利点があります。

20
00:03:55,368 --> 00:04:03,102
まず、各段階ごとにひとつずつ見ていくと、インデックス作成の段階ではチャンク最適化があります。

21
00:04:03,943 --> 00:04:21,177
チャンクを最適化する方法ですが、これは扱う文書の形式によって異なる最適化方法が適用される必要があり、税務を例に挙げると、税務は税法データを扱っているため、非常に多様なメタデータを活用しています。

22
00:04:21,899 --> 00:04:30,605
なんじょうなんこうといった項目から、会計日など、多くのメタデータを活用することができます。

23
00:04:31,725 --> 00:04:40,127
これらの情報をメタデータとして活用しながらチャンクを生成することも、最適化手法のひとつといえます。

24
00:04:40,848 --> 00:04:48,470
プリリトリーバル段階では、先ほど述べたようなクエリを変換したり拡張したりする方法があります。

25
00:04:49,370 --> 00:05:03,638
ポストリトリーバル段階では、検索された複数の文書を重要度に応じて順位付けしたり、生成段階で作成された回答が正しいか検証したりといった工程を追加することで、信頼性を確保することができます。

26
00:05:04,098 --> 00:05:11,862
すべての段階がモジュール化されているため、各段階を独立して改善し、継続的に最適化できるという利点があります。

27
00:05:12,682 --> 00:05:14,983
次はエージェンティックRAGです。

28
00:05:15,923 --> 00:05:31,288
エージェンティックRAGは、RAGをさらに知的にする構造であり、LLMが単に文書を検索するだけでなく、自ら必要なデータを判断し、必要であれば外部データから情報を収集します。

29
00:05:32,328 --> 00:05:41,815
RAGを実行する際に、自ら判断するエージェントを活用してRAGを行う場合、このような構造をエージェンティックRAGと呼びます。

30
00:05:42,736 --> 00:05:50,061
従来のRAGの場合は、ナレッジベースと呼ばれるデータストアから文書を検索して回答していました。

31
00:05:51,002 --> 00:06:02,418
しかし、エージェンティックRAGでは、LLMが自ら追加の検索を行い、必要であれば外部APIまで活用して、より良い回答を生成することができます。

32
00:06:02,858 --> 00:06:20,591
基本的なベクター検索だけでなく、リアルタイムでウェブを検索したり、必要な外部APIを呼び出すといったダイナミックサーチを行い、このように動的により多く、より豊富な情報を収集することで、基本的なRAGに比べて最適な回答を提供することができます。

33
00:06:21,763 --> 00:06:30,328
次はSelf-RAGですが、Self-RAGは従来のRAGシステムに自己検証機能を追加した方式です。

34
00:06:31,168 --> 00:06:46,217
つまり、LLMが単に検索された文書に基づいて回答を生成するのではなく、検索された情報が不十分な場合は質問を再度修正し、生成された回答が正しいかどうかを自ら検証するプロセスを含んでいます。

35
00:06:47,057 --> 00:07:03,765
フローを見てみると、ユーザーからの質問が入ると、まず検索が行われます。 その後、“グレードドキュメント”という、検索された文書の関連性を評価する段階に進みます。これは、検索された文書がユーザーの質問と関連しているかどうかを評価するプロセスです。

36
00:07:04,245 --> 00:07:13,169
関連がある場合は次のステップに進み、関連がない場合はクエリを変換して、変換したクエリで再度検索を行います。

37
00:07:13,369 --> 00:07:25,394
『関連のある文書が検索された』と判断されると、回答の生成に進みますが、生成された回答を基準に再度ハルシネーションに関する評価を行います。

38
00:07:27,094 --> 00:07:38,839
LLMが生成した回答が文書の内容と一致しているかを評価し、一致していなければハルシネーションが発生したとみなして再度回答を生成します。

39
00:07:39,260 --> 00:07:48,844
ハルシネーションのチェック段階で生成された回答が文書の内容と一致していれば、最後に関連性の評価を行います。

40
00:07:50,204 --> 00:08:03,390
最終的に生成された回答とユーザーの質問の間に関連性があるかを評価し、質問とも関連性があると判断されれば、最終的に回答を出力します。

41
00:08:04,211 --> 00:08:26,305
従来のRAGでは、検索された情報をもとに回答を生成することが主なプロセスでしたが、セルフRAGでは検索によって生成された応答の品質を自らモニタリングし、向上させることができる構造になっているため、RAGベースのシステム全体の性能向上に貢献できる機能です。

42
00:08:27,166 --> 00:08:29,307
次はCollective RAGです。

43
00:08:29,667 --> 00:08:39,292
Collective RAGは、検索された文書が不足していたり適切でない場合に、質問を再構成して追加の検索を行う仕組みです。

44
00:08:40,113 --> 00:08:51,913
従来のRAGは一度検索した結果をそのまま使用しますが、Corrective RAGの場合は検索された情報の信頼性を評価し、必要に応じて追加の検索を行います。

45
00:08:52,874 --> 00:08:58,458
フローを見てみると、ユーザーの質問が入力され、まず検索が実行されます。

46
00:09:00,080 --> 00:09:20,359
先ほどのSelf-RAGと同様に、検索された文書が質問と関連しているかどうかを評価し、関連性が高ければ検索された内容で回答を生成し、関連性が低ければ先ほどのSelf-RAGと同じように質問を再構成して再度検索を行います。

47
00:09:21,841 --> 00:09:38,794
このとき、Self-RAGでは質問を変換して再びナレッジベースで検索を行いますが、Corrective RAGの場合は変換された質問で内部ではなく外部のウェブ検索を通じて追加の資料を取得します。

48
00:09:40,536 --> 00:10:01,288
Self-RAGは、LLMが自ら生成した回答を評価し、必要に応じて補完する方法ですが、Corrective RAGの場合は生成された応答に対して追加検索などの外部フィードバックを活用して補完する点が、Self-RAGとの違いと言えます。

49
00:10:01,927 --> 00:10:04,308
最後に、アダプティブRAGです。

50
00:10:05,489 --> 00:10:16,452
アダプティブRAGは、単にベクトル検索だけを行うのではなく、質問の特性に応じてさまざまな検索経路を自動的に選択するRAG構造です。

51
00:10:17,572 --> 00:10:28,057
クエリルーティングは、クエリ分析の段階でユーザーの質問を分析し、質問の特性に応じてそれぞれ異なるRAGフローにルーティングします。

52
00:10:31,081 --> 00:10:46,854
質問がベクターDBにある情報と関連していると判断されれば、従来のRAG検索が行われ、質問がベクターDBにない情報であれば、ウェブ検索やAPI呼び出し、あるいは再度質問を変換するなどの対応が可能です。

53
00:10:49,517 --> 00:10:57,241
LLMが自ら検索経路を判断し、状況に応じて検索プロセスが変化する柔軟なRAGモデルと言えます。

54
00:10:57,702 --> 00:11:26,658
ここに示されているフローを見ると、クエリ分析の段階でVectorDBを検索するか、ウェブ検索をするか、それ以外の方法で回答するかを判断し、RAGが必要だと判断されれば検索を行います。その後、検索結果が関連しているかどうかを確認し、関連があれば回答を生成し、ハルシネーションがあるかどうかなど、セルフRAGの構造まで連携して活用することができます。

55
00:11:27,778 --> 00:11:35,745
質問ごとに最適な検索方式を選択できるようになっているため、システム全体自体を最適化しているとも言えます。

56
00:11:36,245 --> 00:11:46,394
次に、実際の例である税務フローについて簡単にご紹介しようと思いますが、税務も最初は基本的なライブRAG構造から始めました。

57
00:11:47,355 --> 00:11:54,024
今、始めてから数か月が経ち、数か月間の高度化の末にこのような構造が作られました。

58
00:11:54,725 --> 00:11:59,327
この構造も完成版ではなく、現在も引き続き高度化が進められています。

59
00:12:01,028 --> 00:12:16,340
先ほどお話ししたRAGの発展形がすべて組み込まれている構造だと考えていただければと思いますが、ひとつずつ見ていくと、まず質問が入ると、その意図を把握する意図分類エージェントを通じて税務関連の質問かどうかを判断します。

60
00:12:17,921 --> 00:12:25,903
その後、税務関連の質問だと判断されれば、質問に答えるためにどのデータソースで検索を行うかを判断します。

61
00:12:27,203 --> 00:12:42,475
例えば、韓国はにじゅうよんか国と租税条約を結んでいますが、毎回すべての質問で租税条約を検索するのではなく、海外取引に関連する質問の場合にのみ、該当する国の租税条約を確認するように構成されています。

62
00:12:44,278 --> 00:12:59,009
このように、法令、判例、解釈例、租税条約などから検索を行い、検索されたデータが有効か、関連性があるか、有用性があるかといった内容を判断した上で、検索結果を導き出します。

63
00:13:00,570 --> 00:13:12,692
さらに、計算が必要な質問については、回答を生成する際に計算ツールを使用して、より正確な計算ができるようにロジックが構成されています。

64
00:13:13,514 --> 00:13:34,863
このようなフローが作られるまでにはすうか月の時間がかかりました。私たちは自分たちが税務チームの社員だと考え、税務チームの社員であればこのようなフローで業務を進めるだろうと想定しました。そして、このフローをエージェントにどのように組み込めるか、さまざまなアイデアを出し合った末に、現在のような構造が出来上がったと考えています。
